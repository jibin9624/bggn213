---
title: "class09"
author: 'Jibin (PID: A53300326)'
date: "2021/10/27"
output: pdf_document
---

```{r setup, include=FALSE} 
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```

# *Exploratory data analysis*

### Use the read.csv() function to read the CSV (comma-separated values) file containing the data (available from our class website: WisconsinCancer.csv )

```{r}
fna.data <-read.csv("https://bioboot.github.io/bimm143_S20/class-material/WisconsinCancer.csv")
```


### Complete the following code to input the data and store as wisc.df
```{r}
wisc.df <- data.frame (fna.data, row.names=1)
```

### We can use -1 here to remove the first column
```{r}
wisc.data <- wisc.df[,-1]
```

### Create diagnosis vector for later 
```{r}
diagnosis <- factor(wisc.df$diagnosis) 
diagnosis
```

> Q1. How many observations are in this dataset?

```{r}
dim (wisc.data)
```

> Q2. How many of the observations have a malignant diagnosis?

```{r}
table(diagnosis)
```

> Q3. How many variables/features in the data are suffixed with _mean?

```{r}
grep("_mean", colnames(wisc.data))
```

# *Principal Component Analysis*

## Performing PCA

### Check column means and standard deviations

```{r}
colMeans(wisc.data)
apply(wisc.data,2,sd)
```

### Perform PCA on wisc.data by completing the following code

```{r}
wisc.pr <- prcomp(wisc.data, scale=TRUE)
summary(wisc.pr)
```

> Q4. From your results, what proportion of the original variance is captured by the first principal components (PC1)?

### 44.27%


> Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

### 3 PCs are required to describe at least 70% of the original variance in the data.

> Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

### 7 PCs are to describe at least 90% of the original variance in the data.


## Interpreting PCA results

### Create a biplot of the wisc.pr using the biplot() function.

```{r}
biplot(wisc.pr)
```

> Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

## This is a hot mess of a plot and it's diffcult to interpret.


## Scatter plot observations by components 1 and 2

```{r}
plot(wisc.pr$x [,1:2],  xlab = "PC1", ylab = "PC2", col=diagnosis)
plot(wisc.pr$x [,1], wisc.pr$x [,3])
```

> Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

### Repeat for components 1 and 3
```{r}
plot(wisc.pr$x[, 1], wisc.pr$x[, 3], col = diagnosis, 
     xlab = "PC1", ylab = "PC3")
```

## The first plot (PC2 vs PC1) has a cleaner cut separating the two subgroups than this polt, since PC 2 explains more variance in the original data than PC 3.

### Create a data.frame for ggplot

```{r}
df <- as.data.frame(wisc.pr$x)
df$diagnosis <- diagnosis
```

### Make a scatter plot colored by diagnosis
```{r}
library("ggplot2")
ggplot(df) + 
  aes(PC1, PC2, col=diagnosis) + 
  geom_point() 
```

## Variance explained

### Calculate variance of each component

```{r}
pr.var <- wisc.pr$sdev^2
head(pr.var)
```

### Variance explained by each principal component: pve
```{r}
pve <- pr.var / sum(pr.var)
pve
```


### Plot variance explained for each principal component
```{r}
plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```

### Alternative scree plot of the same data, note data driven y-axis
```{r}
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )
```

### ggplot based graph
#install.packages("factoextra")
```{r}
library(factoextra)
fviz_eig(wisc.pr, addlabels = TRUE)
```

# Communicating PCA results

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean?

```{r}
barplot(wisc.pr$rotation[,1], las=2, mar=c(10, 3, 3, 20))
```
### concave.points_mean

> Q10. What is the minimum number of principal components required to explain 80% of the variance of the data

```{r}
var <- summary(wisc.pr)
var$importance
sum(var$importance[3,] <0.8)
```
### So, four at least.

## Hierarchical clustering

### Scale the wisc.data data using the "scale()" function???
```{r}
data.scaled <-scale(wisc.data)
data.dist <- dist(data.scaled)
wisc.hclust <- hclust(data.dist)
```

Results of hierarchical clustering

> Q11. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

```{r}
plot(wisc.hclust)
abline(wisc.hclust, h=18, col="red", lty=2)
```

## Selecting number of clusters

### Use cutree() to cut the tree so that it has 4 clusters. Assign the output to the variable wisc.hclust.clusters.

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, 4)
table(wisc.hclust.clusters, diagnosis)
```

> Q12. Can you find a better cluster vs diagnoses match by cutting into a different number of clusters between 2 and 10?

Perhaps no.

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, 5)
table(wisc.hclust.clusters, diagnosis)
```


> Q13. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

### The method "ward.D2" looked much better, as he two major clusters are more clearly separated in this method

```{r}
plot(hclust(data.dist, method = "average"))
plot(hclust(data.dist, method = "complete"))
plot(hclust(data.dist, method = "single"))
plot(hclust(data.dist, method = "ward.D2"))
```

# OPTIONAL: K-means clustering

## K-means clustering and comparing results

```{r}
wisc.km <- kmeans(wisc.data, centers= 2, nstart= 20)

table(wisc.km$cluster, diagnosis )
table(wisc.km$cluster, wisc.hclust.clusters)
```

> Q14. How well does k-means separate the two diagnoses? How does it compare to your hclust results?

## It works well, but less accurate that hclust.

# Combining methods

Here we aim to combine our PCA results with clustering. Essentially, we are going to cluster in "PC", that is cluster on the results `wisc.pr`.


```{r}
plot(wisc.pr$x[,1:2], col= diagnosis)
```

## Clustering on PCA results

I will use 4 PCs and `hclust()` and `dist()` as an input.

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:4]), method = "ward.D2")
```

```{r}
plot(wisc.pr.hclust)
abline(h=80, col="red")
```
Let's find our cluster membership vector by cutting this tree into k=2 groups.

```{r}
grps <- cutree(wisc.pr.hclust, k=2)
table(grps)
table(grps, diagnosis)
plot(wisc.pr$x[,1:2], col=grps)
plot(wisc.pr$x[,1:2], col=diagnosis)
```

To match things up we can turn our groups into a factor and reorder the levels so cluster 2 comes first and thus gets the first color (black) and cluster 1 gets the second color (red).

```{r}
g <- as.factor(grps)
levels(g)
```
```{r}
g <- relevel(g,2)
levels(g)
plot(wisc.pr$x[,1:2], col=g)
plot(wisc.pr$x[,1:2], col=diagnosis)
```


    diagnosis
grps   B   M
   1   6 165
   2 351  47

TP: 165, FP:6
TN: 351, FN: 47

**Accuracy**, essentially how many did we get correct?

**Sensitivity**: TP/(TP+FN)

**Specificity**: TN/(TN+FN)

```{r}
# **Accuracy**: (TP+TN)/total cases
# **Sensitivity**: TP/(TP+FN)
# **Specificity**: TN/(TN+FN)
Accuracy <- (165+351)/nrow(wisc.data)*100
Sensitivity <- (165)/(165+47)*100
Specificity <- (351)/(351+47)*100
evulation <- rbind(Accuracy, Sensitivity, Specificity)
evulation 
```

## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method="ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=2)
table(wisc.pr.hclust.clusters, diagnosis)
```

```{r}
# **Accuracy**: (TP+TN)/total cases
# **Sensitivity**: TP/(TP+FN)
# **Specificity**: TN/(TN+FN)
Accuracy <- (188+329)/nrow(wisc.data)*100
Sensitivity <- (188)/(188+24)*100
Specificity <- (329)/(329+24)*100
evulation <- rbind(Accuracy, Sensitivity, Specificity)
evulation 
```

> Q15. How well does the newly created model with four clusters separate out the two diagnoses?

It looked good, with higher sensitivity and specificity.


> Q16. How well do the k-means and hierarchical clustering models you created in previous sections (i.e. before PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.km$cluster and wisc.hclust.clusters) with the vector containing the actual diagnoses.

```{r}
table(wisc.km$cluster, diagnosis)
```

```{r}
# **Accuracy**: (TP+TN)/total cases
# **Sensitivity**: TP/(TP+FN)
# **Specificity**: TN/(TN+FN)
Accuracy <- (130+356)/nrow(wisc.data)*100
Sensitivity <- (130)/(130+82)*100
Specificity <- (356)/(356+82)*100
evulation <- rbind(Accuracy, Sensitivity, Specificity)
evulation 
```

```{r}
table(wisc.hclust.clusters, diagnosis)
```


```{r}
# **Accuracy**: (TP+TN)/total cases
# **Sensitivity**: TP/(TP+FN)
# **Specificity**: TN/(TN+FN)
Accuracy <- (165+343)/nrow(wisc.data)*100
Sensitivity <- (165)/(165+40)*100
Specificity <- (343)/(343+40)*100
evulation <- rbind(Accuracy, Sensitivity, Specificity)
evulation 
```

> Q17. Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

Using the distance along the first 7 PCs for clustering give the best specificity and sensitivity.

# Prediction

We will use the `predict()` function that will take our PCA model from before and new cancer cell data and project

```{r}
#url <- "new_samples.csv"
url <- "https://tinyurl.com/new-samples-CSV"
new <- read.csv(url)
npc <- predict(wisc.pr, newdata=new)
npc
```

Now add these new samples to our PCA plot

```{r}
plot(wisc.pr$x[,1:2], col=g)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], labels=c(1,2), col="white")
```

